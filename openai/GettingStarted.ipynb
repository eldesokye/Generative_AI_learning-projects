{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d193b8",
   "metadata": {},
   "source": [
    "### Getting started with langchain and Open Ai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b44e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]= os.getenv(\"OPEN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openrouter.ai/api/v1\"\n",
    "## langsmith Tracking \n",
    "os.environ[\"LANGCHAIN_API_KEY\"]= os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]= \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"OPENAI_MODEL_NAME\"]=\"openai/gpt-oss-20b:free\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1944fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\365 projects\\lang chain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001A8F0192860> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A889812890> root_client=<openai.OpenAI object at 0x000001A8F01923E0> root_async_client=<openai.AsyncOpenAI object at 0x000001A88AD9BD30> model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://openrouter.ai/api/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c021c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\365 projects\\lang chain\\venv\\lib\\site-packages\\pydantic\\v1\\main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm just a computer program, so I don't have feelings or emotions, but I'm here to help you with any questions or tasks you have. How can I assist you today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input and get response from llm \n",
    "llm.invoke(\"How are YOu ?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c21a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"what is generative AI?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff503c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to artificial intelligence systems that are able to generate new content, such as images, text, or music, based on input data. These systems can create original material by learning patterns and styles from existing data, and then generating new outputs that are similar or entirely new. Generative AI can be used in various applications, such as creating art, designing products, or generating realistic human-like conversations.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee872ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engneer . Provide me answers based on the question . '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chat prompt template \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI engneer . Provide me answers based on the question . \"),\n",
    "        (\"user\",\"{input}\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c883828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not familiar with the term \"langsmith.\" Could you provide more context or details so I can better assist you?\n"
     ]
    }
   ],
   "source": [
    "## chain is combine from prompt and llm \n",
    "\n",
    "chain = prompt|llm\n",
    "\n",
    "result = chain.invoke({\"input\":\"Can you tell me about langsmith?\"}).content\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4d76af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "369b553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is a branch of artificial intelligence that focuses on developing algorithms that allow computers to learn from and make decisions or predictions based on data without being explicitly programmed. ML algorithms can recognize patterns in data and make intelligent decisions or predictions. There are several types of machine learning, including supervised learning, unsupervised learning, and reinforcement learning. ML is widely used in various fields, such as healthcare, finance, and marketing, to extract valuable insights from large datasets and automate decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "result = chain.invoke({\"input\":\"Can you tell me about ML?\"})\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
