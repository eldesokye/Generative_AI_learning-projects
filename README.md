# Generative_AI_learning-projects

# Generative AI Learning Projects ğŸš€

This repository is a **hands-on learning collection of Generative AI, LLMs, and LangChain projects**, covering everything from basic chatbot implementations to **RAG (Retrieval-Augmented Generation)**, **Conversational Q&A**, and **LCEL-based applications**.

It is structured as a modular playground for experimenting with **OpenAI, Ollama, LangChain, vector retrieval, and document-based Q&A systems**.

---

## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ 4.RAG Document Q&A
â”‚   â”œâ”€â”€ research_papers
â”‚   â”‚   â”œâ”€â”€ Attention.pdf
â”‚   â”‚   â””â”€â”€ LLM.pdf
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ building_chatbot
â”‚   â”œâ”€â”€ 1-chatbots.ipynb
â”‚   â””â”€â”€ vectorRetriever.ipynb
â”‚
â”œâ”€â”€ Conversational_Q&A_chatbot
â”‚   â”œâ”€â”€ 1-Langchain
â”‚   â””â”€â”€ conversation_Q&A.ipynb
â”‚
â”œâ”€â”€ langchain Projects
â”‚   â””â”€â”€ 1-Q&A Chatbot
â”‚       â”œâ”€â”€ venv
â”‚       â”œâ”€â”€ .env
â”‚       â”œâ”€â”€ app.py
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ LCEL
â”‚   â”œâ”€â”€ serve.py
â”‚   â””â”€â”€ simplellmLCEL.ipynb
â”‚
â”œâ”€â”€ myenv311
â”‚
â”œâ”€â”€ ollama_llm
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ openai
â”‚   â”œâ”€â”€ GettingStarted.ipynb
â”‚   â””â”€â”€ simple app.ipynb
â”‚
â”œâ”€â”€ Q&A chatbot
â”‚   â””â”€â”€ venv
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE
âœ¨ Key Features

ğŸ”¹ LLM Fundamentals

Basic chatbot implementations

OpenAI API usage

Ollama local LLM integration

ğŸ”¹ LangChain Projects

Prompt chaining

Conversational memory

Vector-based retrieval

Q&A chatbots

ğŸ”¹ RAG (Retrieval-Augmented Generation)

Document ingestion (PDFs)

Vector stores

Research paper-based Q&A

ğŸ”¹ LCEL (LangChain Expression Language)

Lightweight, composable LLM pipelines

Server-based deployment example

ğŸ§  Technologies Used

Python 3.10+

LangChain

OpenAI API

Ollama

FAISS / Vector Retrieval

Jupyter Notebooks

dotenv

FastAPI / CLI apps (where applicable)

âš™ï¸ Setup & Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/Generative_AI_learning-projects.git
cd Generative_AI_learning-projects

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


(Some projects maintain their own requirements.txt inside subfolders.)

ğŸ”‘ Environment Variables

Create a .env file in the relevant project folder:

OPENAI_API_KEY=your_openai_api_key


For Ollama-based projects, ensure Ollama is running locally.

â–¶ï¸ Running Projects
Example: RAG Document Q&A
cd "4.RAG Document Q&A"
python app.py

Example: LangChain Q&A Chatbot
cd "langchain Projects/1-Q&A Chatbot"
python app.py

Jupyter Notebooks
jupyter notebook

ğŸ“Œ Learning Goals

This repository is designed to:

Understand LLM workflows

Build real-world AI chatbots

Learn retrieval and document grounding

Experiment with local vs cloud LLMs

Practice LangChain best practices

ğŸ›£ï¸ Future Improvements

 Add Streamlit UI for chatbots

 Add evaluation metrics

 Dockerize applications

 Centralized requirements management

 Deployment examples (AWS / GCP)

ğŸ¤ Contributing

Contributions are welcome!
Feel free to fork the repository and submit a pull request.

ğŸ“„ License

This project is licensed under the MIT License.
See the LICENSE file for details.

ğŸ‘¤ Author
Hesham Yahya Eldesoky
AI / ML Enthusiast | Generative AI Developer